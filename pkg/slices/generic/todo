package generic



	Specification{
		FunctionName: "",
		StandardPath: Behavior{
			Description: "",
			Expectation: func(t *testing.T){
				t.Skip()
			},
		},
		AlternativePath: Behavior{
			Description: "",
			Expectation: func(t *testing.T){
				t.Skip()
			},
		},
	},

/*

AnyS*
AllS*
AutoCorrelate *
CrossCorrelate *
Convolute *
CountS *
DistinctS *
FilterS *
FindIndexS *
FindIndices *
FindIndicesS *
FirstS *
Flatten *
ForEachI *
ForEachIC
ForEachIR
ForEachCIR
GroupS *
InsertAfterS *
InsertBeforeS *
IntersectionS *
IsProperSubsetS*
IsProperSupersetS*
IsSubsetS*
IsSupersetS*
LastS*
MapC
MapCI
MapI
NoneS*
NoneC*
PartitionS*
RemoveS *
RemoveFirst *
RemoveFirstS *
SplitAfterS*  
SplitBeforeS*
SkipUntil *
TakeUntil *

Pop
Push
Reduce
RemoveAt
Reverse
Skip
SkipWhile
Some
Sort
SplitAfter
SplitAt
SplitBefore
String
Swap
SwapIndex
Tail
Take
TakeWhile
Union
Unzip
WindowedC
WindowedL
WindowedR
Zip

*/


Ripe for performance improvement
Any <- Can do a parallel search, splitting the list into chunks, each scanned by a different channel
Count <- Can be split and counted in parallel
Difference <- currently has a minor optimiation to only scan the shorter list. However, other strategies could improve performance quite a bit.
Group <- internal hashing is really naive. Could be optimized if hashes were sorted.
Intersection <- Currently uses Any() to determine if an element has already been added. This has a low memory overhead, but a huge performance pentalty. A better approach would be to store the matches in a map then convert the map to a slice in a single pass.